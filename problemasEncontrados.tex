%En problema con solución actual plantearía entre otras cosas que el best first search tiene que ser correcto para cualquier heuristica y que eso no se cumpía. Plantearía el suite de regresión que armaron y com tuvieron que harnesear el tema de la heuristica para mostrar algunos bugs
En este capítulo vamos a mostrar un vistazo de nuestra suite de regresión y tratar de construir una intuición de los problemas encontrados con el algoritmo de exploración anterior, ayudándonos con ejemplos y gráficos. En todos los gráficos siguientes vamos a utilizar las letras $c$, $u$, para denotar si una transición es controlable o no, respectivamente; en caso de no especificar letra para una transición es porque su controlabilidad no afecta el resultado del ejemplo.

\section{Heurística de debugging}
Como dijimos en el capítulo anterior, el algoritmo de DCS debe ser agnóstico a la heurística. Al comenzar nuestro trabajo en el proyecto y una vez que pudimos generar un conocimiento sobre el pseudocódigo nos percatamos de ciertos casos borde que no iban a ser bien resueltos, o esto suponíamos. Sin embargo, al correr dichos casos el resultado era correcto, esto se debía a que la heurística era muy buena y llevaba al error directamente; entonces no caía en nuestra ``trampa''.

En función de poner a prueba sólo el algoritmo de exploración desarrollamos una heurística de debugging o \textit{Dummy}. La misma ordena las transiciones a explorar alfabéticamente, dejando primero las no controlables pero no mira ninguna información sobre distancia a marcados o error. Decidimos dejar el ordenamiento de no controlables primero ya que esto no es heurístico, se sabe perfectamente qué transiciones son controlables y cuáles no.

A partir de entonces usamos los nombres de las transiciones para explorar nuestros casos de test de la forma que nos interesaba. 

\section{Suite de regresión}
A continuación mostraremos algunos resultados obtenidos a partir de nuestra batería de tests. La misma cuenta con \totalTests tests, todos casos sumamente especiales o variaciones pequeñas de los mismos que son interesantes desde un punto de vista implementativo. En el capítulo \ref{chpt:implementation} se puede encontrar más detalle sobre ellos y cómo los desarrollamos, junto con ejemplos de especificación del modelo.

Como podemos ver en la tabla \ref{tab:resultadosTest} los tests se comportan diferente según la heurística que se use, \textit{RA} o \textit{Dummy}. Exception refiere a un error implementativo que surgía en tiempo de ejecución, específicamente Concurrent Modification Exception, esto pasaba porque se modificaba a la vez que se recorría un conjunto de estados. \textit{Falsos  no controlables} son casos que deberían haber dado controlable y no fue así, la inversa para \textit{falsos controlables}.

%TODO acomodar estos parrafos mejor y agregar más explicación sobre las heurísticas

TIENE SENTIDO MOSTRAR ESTO? los tests se hicieron para cada versión particular, por eso algunos van a andar en el original y otros no. Tiene sentido ir mostrando el progreso y por qué rompían cada uno en cada versión aunque esto me parece un poco mucho. Un punto medio sería explicar el por qué de cada test y listo.

Cabe destacar que, además, fallan en distintos tests. Hay 4 tests que dieron falsos no controlables con \textit{RA} pero funcionaron correctamente con \textit{Dummy}. Por su lado \textit{Dummy} falla en 4 tests ``nuevos'' en esta categoría.

\begin{table}
    \centering
    \begin{tabular}{|l|c|c|c|}
    \hline
         & Exception & Falsos no controlables & Falsos controlables \\ \hline
        RA & 7 & 7 & - \\ \hline
        Dummy & 3 & 7 & 3 \\ 
    \hline
    \end{tabular}
    \caption{Resumen fallos del suite}
    \label{tab:resultadosTest}
\end{table}

\section{Puntos a resolver}
Gracias a esta suite de tests pudimos encontrar que la exploración fallaba en tres puntos importantes:
\begin{itemize}
 \item Falencias al encontrar errores
 \item Propagación local
 \item Falta de completitud en la exploración en casos donde era necesario seguir.
 \item detección de estados ganadores poco robusta.
\end{itemize}

% FALENCIAS AL ENCONTRAR ERRORES
En cuanto a agregar estados al conjunto $\Errors$ la inadvertencia se debía a que no sacaba conclusión alguna al haber explorado todo un sub-autómata, por ende al propagar información desde otra rama se podría llegar a un resultado erróneo. 

Para comprender mejor observar la figura \ref{fig:falenciasErrores} donde desde el estado e tenemos dos sub-ramas a explorar. Si se mira primero la rama de abajo y no lo marcamos como error, a pesar de estar completamente explorado, entonces al mirar la de arriba diremos que es goal y propagaremos dicha información, equivocadamente, más allá de e. 

Cabe destacar que esto era posible debido a que no se requería que un estado hijo tenga conclusión\footnote{Es decir, esté en el conjunto $\Goals$ o $\Errors$} para seguir propagando, es decir, bastaba con que haya sido explorado alguna vez y se asumía lo mejor.
\begin{figure}[htb]
 \centering
 \includegraphics[width=\linewidth/2]{figures/FalenciasErrores.pdf}
 \caption{Caso no controlable que anteriormente propagaba Goal}
 \label{fig:falenciasErrores}
\end{figure}

% PROPAGACION LOCAL
Por otro lado, al propagar tenía una mirada local, perdiendo información sobre lo que sucede dentro del conjunto. Es así que no podía reconocer casos donde, por ejemplo: hay un loop controlable entre dos estados, el cual se explora primero, y uno de ellos va controlablemente a un error. En este caso es obvio que todo debe ser error pero según la mirada local ambos tienen \textit{una forma de escapar del error}, el otro estado del conjunto. Para una aclaración visual ver la fugura \ref{fig:propagarError}.

Equivalentemente tampoco funciona reconociendo $\Goals$, en la figura \ref{fig:propagarGoal} se puede ver un ejemplo. El estado $2$ llega al estado marcado $3$, pero no puede forzarlo. Por ser non-blocking esto no nos molestaría y el modelo debería ser controlable. Pero si miramos localmente al propagar $Goal$ desde $3$, no sabemos dónde nos lleva la transición no controlable, y deberíamos suponer lo peor.

En conclusión, es difícil decidir dónde hacer el corte. Son muchos casos y no se puede, localmente, distinguirlos a todos. Por ende es necesario un algoritmo más inteligente, con una mirada global del conjunto a propagar.
\begin{figure}[htb]
	\centering
	\makebox[\linewidth][c]{%
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figures/PropagarError.pdf}  
		\caption{Propagar errores}
		\label{fig:propagarError}
	\end{subfigure}
	\begin{subfigure}[t]{.5\textwidth}
		\centering
		\includegraphics[width=\linewidth]{figures/PropagarGoal.pdf}  
		\caption{Propagar goals}
		\label{fig:propagarGoal}
	\end{subfigure}
	}
	\caption{Problemas de propagación local.}
	\label{fig:propagacionLocal}
\end{figure}

% FALTA DE COMPLETITUD
Respecto a la falta de completitud, queda claro que teniendo una conclusión para cada uno de los estados hijos del inicial podemos definir si el problema es o no controlable. 
Lo que sucedía era que al tener conclusiones erróneas y problemas de propagación había ciertos casos donde, según el algoritmo de exploración el problema era controlable pero al llegar al constructor del controlador se daba cuenta que había estados a los cuales les faltaba exploración y que, de hecho, tenían transiciones no controlables a estados sin mirar. 
Llegado ese punto devolvía que no había controlador, cuando de seguir explorando hubiese visto que lo que faltaba era algo ganador. Un ejemplo particular de esto puede verse en la figura \ref{fig:faltaCompletitud}, al terminar la exploración se concluyó que era controlable, sin embargo al querer construir el controlador se descubre que el estado $1$ tiene una no controlable por explorar, devolviendo entonces que no existe controlador. 

\begin{figure}[htb]
 \centering
 \includegraphics[width=\linewidth/2]{figures/faltaDeCompletitud.pdf}
 \caption{Ejemplo de falta de completitud, los estados en gris son los faltantes por explorar.}
 \label{fig:faltaCompletitud}
\end{figure}

Finalmente, la detección de loops con estados ganadores es una pieza central del problema, y tampoco puede solucionarse con una mirada local. Originalmente, la primera versión del pseudocódigo daba una descripción declarativa de los estados a encontrar (ver listng \ref{lst:viejoMCCC}). Esta descripción de los estados en un loop ganador es correcta, pero no resulta claro como implementarla. En particular, fue claro al incrementar la batería de tests que la detección de loops ganadores necesitaba una modificación.

Luego de varias intentos más veloces (como ejemplo ver el pseudocódigo de \texttt{findNewErrorsIn($loops$)}) pero que presentaban fallas, llegamos a la conclusión de utilizar un algoritmo de punto fijo clásico (similar a listing \ref{lst:classical}) pero con una planta reducida. Como se verá más adelante, corremos el algoritmo clásico sobre una versión optimista que asume que toda transición no explorada es perdedora, y de los estados ya explorados solo tomamos en cuenta un grupo reducido que forma un loop sobre la última transición explorada. Este enfoque otorga la completitud del algoritmo tradicional mientras que sostiene la eficiencia de la exploración on-the-fly.

\begin{lstlisting}[language={pseudocode},label={lst:viejoMCCC},caption={vieja descripción estados ganadores},float=ht, frame=single]
function buildMCCC($e, e'$):
  let $C$ such that
    $C = \{ e_i \mid (e' \runw{w}{\structure} e_i \runw{w'}{\structure} e \vee e \runw{w}{\structure} e_i \runw{w'}{\structure} e') \wedge $extendsCCC($e_i,C \cup \Goals$)$ \wedge$
    $(\exists w \ldot e \runw{w}{\structure} e_m \wedge e_m \in M_E \cap (C \cup \Goals)) \}$
  return $C$
  
function extendsCCC($e, C$):
  return $(\exists \l \ldot e \step{\l}{E} e' \wedge e' \in C) \wedge (\forall \l_u \in A_U \ldot e \step{\l_u}{E} e' \Rightarrow e' \in C)$

\end{lstlisting}





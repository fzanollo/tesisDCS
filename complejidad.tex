La complejidad del algoritmo en el Listing~\ref{lst:dcs} está acotada por
	$O(|S_E|^3 
	\times |A_E|^2)$, donde $|S_E|$ y $|A_E|$ son el número de estados y eventos en
	$E$. Esto se desprende del hecho de que el loop principal se ejecuta a lo sumo una vez por transición (i.e., 
	$|T_{E}|$), que $|T_{E}| \leq|S_{E}|\times|A_E|$ y que la complejidad de una iteración del loop está acotada por $O(|S_{ES}|^2 \times |A_{E}|) \leq O(|S_{E}|^2 \times 
	|A_{E}|) $.

La complejidad de cada iteración está acotada por la de \texttt{findNewGoalsIn}, la función más compleja de todas las llamadas durante cada iteración: \texttt{propagateError}, \texttt{canReach},
\texttt{propagateGoal}, 
	 \texttt{getMaxLoop}, \texttt{canBeWinningLoop}, 
	\texttt{findNewGoalsIn}, y \texttt{findNewErrorsIn}.
	
A continuación presentamos un análisis detallado de la complejidad de cada sub-rutina: 

Usaremos $|S_C|$ y $|T_C|$ para referirnos al número de estados y transiciones de una exploración parcial $C$ de la planta $E$.

\begin{enumerate}
	\item O(findNewGoalsIn($loop$))$ <= O(|S_{ES}| \times |T_{ES}|)$: 
	Un punto fijo progresivamente remueve todos los estados que no son ganadores en $\unexploredToBottom{\structure'}$.
	En el peor caso se deben remover $|S_{ES}|$ estados, y el costo de remover cada un estado está acotado por $|T_{ES}|$.
	Cada iteración ejecuta otro punto fijo que va quitando los estados que son perdedores (en $\unexploredToBottom{\structure'}$)
	o son inalcanzables desde dentro de $C$.
	Esto se obtiene al chequear todas las transiciones entrantes y salientes para cada estado ($O(|T_{ES}|)$). 
	Luego, cada iteración del primer punto fijo realiza una exploración "backwards $BFS$" sobre $C$ ($O(|T_{ES}|)$), comenzando desde los estados marcados de $C$ (o estados que tienen un hijo en $\Goals$). Cuando la exploración termina, todos los estados de $C$ que no fueron alcanzados son removidos.
	
	\item O(findNewErrorsIn($loops$))$ <= O(|S_{ES}| \times |A_E|)$: Simplemente iteramos sobre todos los estados del loop y chequeamos si hay al menos un estado con un hijo NONE fuera del loop. Como nuestro autómata es determinístico sabemos que para cualquier estado $s$, 
	$|hijos(s)|<=|A_E|$ (la cantidad de eventos). Además, la cantidad de estados del $loops$ está acotada por $S_{ES}$.
	
	\item O(propagateGoals($newGoals$))$ <= O(|S_{ES}| \times |T_{ES}|)$: 
	El razonamiento es similar al de findNewGoalsIn, pero ahora iterando sobre todos los ancestros-NONE, cuya cantidad está acotada por $S_{ES}$. Luego, la complejidad de la función está acotada por $O(|S_{ES}| \times (O($ 
	iteración$)))$. 
	
	Cada iteración quita los estados $s$ que son forzados a perder en un paso o no pueden alcanzar un estado $goal$ dentro de $C$. La
	implementación logra esto con complejidad $O(|T_{ES}|)$. Revisar si cada estado $s$ está forzado a perder en un paso solo requiere chequear sus hijos ($O(|T_{ES}|)$ ). Chequear cuales estados pueden alcanzar un goal requiere una búsqueda en anchura que comienza en los estados de $C$ con un hijo $goal$ y propagar hacia los ancestros (dentro de $C$).
	En el peor caso esto requiere iterar sobre todas las transiciones $|T_{ES}|$ .
	
	En conclusón $O($ iteración$) = |T_{ES}|$  y O(propagateGoals($newGoals$))$ \leq O(|S_{ES}| \times 
	|T_{ES}|)$.
	
	\item O(propagateErrors($newErrors$))$ = O(|S_{ES}| \times |T_{ES}|))$: Esta función es similar a propagateGoals y se aplica el mismo razonamiento.	
	
	\item O(canReach($e, e'$))$ = O(|T_{ES}|)$: Simplemente requiere una búsqueda en anchura sobre las transiciones salientes.
	
	\item O(getMaxLoop($e, e'$))$ = O(|T_{ES}|)$: 
	Comenzando por $e$ se puede realizar una búsqueda en anchura para iterar sobre todos sus ancestros, cortando la exploración cuando se llega a un estado GOAL, ERROR o $e'$. 
	
	
	\item O(canBeWinningLoop($loops$))$ = O(|T_{ES}|)$: Requiere verificar si hay un estado marcado en $loops$ ($|loops| \leq |S_{ES}|$) y ver todos los hijos de estados en $loops$ para ver si alguno es un estado en GOAL o ERROR ($|T_{ES}|$).  
	Tenemos entonces $O(|S_{ES}| + |T_{ES}|) = O(|T_{ES}|)$
	
\end{enumerate}

Entonces concluimos que la complejidad máxima de todas las funciones está acotada por $O(|S_{ES}| \times |T_{ES}|)$  

Considerando que $|T_{ES}| \leq|S_{ES}|\times|A_E|$ y que en el peor caso para el tamaño de $ES$ se da cuando $ES=E$, entonces todas las iteraciones del loop principal están acotadas por $O(|S_E|^2\times|A_E|)$.

Finalmente, la complejidad total de nuestro algoritmo es: $O(|T_E| \times (|S_E|^2 \times |A_E|)) \leq O(|S_E|^3 \times |A_E|^2)$.

Previamente, \cite{Huang:2007:Optimal}
presentó una solución teórica para construir un director optimal en $O(|X| \times |\Sigma| × (|X m − X t | + 1))$ (donde $X=S_E$, $\Sigma = A_E$ y $X_m - X_t$ es el número de 
estados marcados que no son terminales. 
Luego, comparando \cite{Huang:2007:Optimal} 
con la última iteración de nuestro enfoque (cuando $ES=E$), la diferencia reside en la relación entre
$|S_E|$ y $|X_m - X_t|$. 
Aunque $|S_E| \geq |X_m - X_t|$, el número de estados marcados no terminales puede sufrir proporcionalmente la misma explosión que los estados de la planta.
Por lo tanto, en el peor caso, $O(|S_E|) = O(|X_m - X_t|)$. Lo que permite la afirmación de que la última iteración de nuestro algoritmo tiene una complejidad peor caso comparable a la complejidad de 
\cite{Huang:2007:Optimal}.
Sin embargo, nuestro trabajo sufre una penalidad a nivel de complejidad a raíz de intentar resolver el problema antes de conocer la composición completa de la planta. En \DCS el loop es ejecuta hasta
|$T_E$| veces, cada vez que a $\structure$ se le agrega una transición. Este es el costo en complejidad a pagar por la construcción on-the-fly. 
Los resultados experimentales muestran que esta complejidad teórica adicional puede compensarse con el tiempo ganado al evitar la construcción completa del state space, y en consecuencia tener iteraciones menos costosas sobre un espacio menor. 








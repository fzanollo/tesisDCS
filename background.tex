A continuación definimos formalmente el problema composicional de síntesis de controlador nonblocking.

\begin{definition}[Automata Deterministico] \label{def:automata}
	Un \k{automata deterministico} es una tupla $T = (S_T, A_T, \D_T, \init{t}, M_T)$, donde:
	\begin{itemize*}[label=]
		
		\item $S_T$ es un \k{conjunto finito de estados};
		
		\item $A_T$ es el \k{conjunto de eventos} del autómata;
		
		\item $\D_T \C (S_T \x A_T \x S_T)$ es una \k{función de transición};
		
		\item $\init{t} \in S_T$ es el \k{estado inicial}; y
		
		\item $M_T \C S_T$ es un conjunto de \k{estados marcados}.
		
	\end{itemize*}
	
\end{definition}

\begin{notation}[Pasos y corridas] \label{not:paso}
	
	$\!\!$Notamos $(t,\l,t') {\in}\!\! \D_T$ como $t \step{\l}{T} t'$ y lo llamamos \k{paso}.
	A su vez, una \k{corrida} de una palabra $w = \l_0,\ldots,\l_k$ en $T$, es una secuencia de pasos tal que $t_i \step{\l_i}{T} t_{i+1}$ para todo $0 \leq i \leq k$, notado como $t_0 \runw{w}{T} t_{k+1}$.
	
\end{notation}

Los autómatas definen un lenguaje, un conjunto de palabras, que aceptan. Dado un conjunto de eventos $A$, notamos con $A^*$ al conjunto de palabras finitas de eventos de $A$. El lenguaje generado por un autómata $T$ es el conjunto de palabras formadas por sus eventos que cumplen $\D_T$. Formalmente, si $w \in A_T^*$, entonces $w \in \L(T)$ si y solo si existe una corrida para $w$ comenzando desde el estado inicial $\init{t}$ de $T$, que notamos $\init{t} \runw{w}{T} t_{k+1}$.


\begin{definition} [Composición Paralela] \label{def:parcomp}
	La \k{composición paralela} $(\|)$ de dos autómatas $T$ y $Q$ es un operador simétrico y asociativo que produce un autómata $T \| Q = (S_T {\times} S_Q, A_T {\cup} 
	A_Q, \D_{T\|Q}, \<\init{t},\init{q}\>, M_T {\times} M_Q)$, donde $\D_{T\|Q}$ es la menor relación que satisface las siguientes reglas (omitimos la versión simétrica de la primera regla):
	
	\begin{normalsize}
		\centering
		\vspace{-18pt}
		\hspace{-50pt}
		\begin{minipage}{0.30\linewidth}
			\[ 
			\frac{t \step{\l}{T} t'}{\<t,q\> {\step{\l}{T\|Q}} \<t'\!,\!q\> }{{\scriptstyle \l \in A_{T} {\setminus} A_{Q}}} 
			\]
		\end{minipage} 
		\hspace{40pt}
		%\begin{minipage}{0.30\linewidth}
		%\[ 
		%\frac{q \step{\l}{Q} q'}{\<t,q\> \step{\l}{T\|Q} \<t,q'\>}{{\scriptstyle \l \in A_{\!Q} 
		%{\setminus} A_{T}}} 
		%\]
		%\end{minipage} \\[-6pt]
		%\hspace{-20pt}
		\begin{minipage}{0.30\linewidth}
			\[ 
			\frac{t \step{\l}{T} t' \quad q \step{\l}{Q} q'}{\<t,q\> \step{\l}{T\|Q} \<t',q'\>}{{\scriptstyle \l \in A_{T} {\cap} A_{Q}}}
			\]
		\end{minipage} \\[15pt]
	\end{normalsize}
\end{definition}

\section{Controlador objetivo}

Dado un autómata y una partición de sus eventos en dos subconjuntos: $controlables$ y $no controlables$, lo que buscamos es un $controlador$ (supervisor) que restrinja el vocabulario aceptado de forma de mantener un camino posible a los estados marcados del autómata.

Un controlador observa las transiciones no controlables y deshabilita alguna transiciones controlables para generar una planta restringida. Una palabra $w$ pertenece al lenguaje generado por $T$ restringido por una función del controlador $\sigma : A_T^* \into 2^{A_T}$ (anotado como $\L^\sigma(T)$) si cada prefijo de $w$ ``sobrevive'' a $\sigma$.
Formalmente, sea $w = \l_0,\ldots,\l_k$ una palabra en $\L(T)$, entonces $w \in \L^\sigma(T)$ si y solo si para todo $0 \leq i \leq k$:
$
\init{t} \run{\,\l_0}{\l_i}{T} t_{i+1} \wedge \l_i \in \sigma(\l_0,\ldots,\l_{i-1})
$

\begin{definition}[Problema de Control Supervisado] \label{def:control-problem}
	Un \k{Problema de Control Supervisado} composicional es una tupla $\E = (E, A_E^C)$, donde $E$ es un conjunto de autómatas $\{E_0,\ldots,E_n\}$ (podemos abusar la notación y usar $E = (S_E,A_E,\D_E,\init{e},M_E)$ para referirnos a la composición $E_0\|\ldots\|E_n$), y $A_E^C \C A_E$ es el conjunto de eventos controlables (i.e., $A_E^U = A_E \setminus A_E^C$ es el conjunto de eventos no controlables).
	Una solución para $\E$ es un supervisor $\sigma : A_E^* \into 2^{A_E}$, tal que $\sigma$ es:
	\begin{itemize}[itemsep=4pt,topsep=-8pt]
		
		\item \k{Controlable}: $A_E^U \C \sigma(w)$ con $w \in A_E^*$; y
		
		\item \k{Nonblocking}: para cada palabra $w \in \L^\sigma(E)$ existe una palabra no vacía $w' \in A_E^*$ tal que, la concatenación $ww' \in \L^\sigma(E)$ y $\init{e} \runw{\;ww'}{E} e_m$ con $e_m \in M_E$ (i.e., un estado marcado de $E$).
		
	\end{itemize}
	
\end{definition}

Podemos pensar en un controlador non-blocking como un jugador optimista. Se encarga de no perder, y mientras tenga un futuro camino posible que lo lleva al destino buscado, considera que está ganando.

Es clave entender que en el problema a tratar, la posición de "tablas" del ajedrez, en la que ambos jugadores repiten sus jugadas 50 veces, se considera ganadora si todavía hay opción de dar un jaque mate. Si repetimos nuestras jugadas y todavía tengo dos torres considero que gané el partido, porque eventualmente mi oponente podría cansarse y dejarme ganar. Si repetimos nuestras jugadas pero solo tengo mi rey, no hay forma de dar mate, no puedo extender esta "palabra", esta partida, de forma de dar mate, y considero que perdí.

Es importante notar que como se busca que cualquier palabra sea extendible a otro estado marcado, lo que se busca es pasar por algún estado marcado infinitas veces. O sea, un estado 'e' marcado que tenga un camino para que el jugador pueda volver controlablemente al mismo estado 'e'.

Por esto, las estructuras claves que analizamos en nuestro algoritmo son los ciclos ($loops$), ya que los primeros estados ganadores son aquellos que están en un loop controlable con un estado marcado dentro. Luego anotamos como ganadores también a cualquier estado que controlablemente alcanza un estado ganador.

Los ciclos también son esenciales para encontrar los estados perdedores, ya que la única forma de que un estado sea perdedor es que no pueda alcanzar un estado ganador. En otras palabras, los estados perdedores son aquellos que forman parte de un loop que no tiene estados marcados ni transiciones salientes.

De forma más concreta, en nuestro algoritmo, un ciclo del cual el jugador no puede escapar, pero desde el cual existe un camino hacia un estado ganador, se considera ganador.

\section{Algoritmo monolítico}

Una solución a este problema (o problemas similares), ampliamente estudiada[refs paper funcional, tesis dipi, buchiGames] se basa en un doble punto fijo. Ya que en la solución clásica se conoce toda la planta compuesta, se parte de la base de todos los estados marcados como objetivos, y a partir de ellos se desde que estados un controlador puede forzar a llegar a los estados marcados al menos una vez.

De los estados que no pueden forzar a los marcados, ya sabiendo que son estados donde gana el ambiente, se pueden retirar del punto fijo, y también a cualquier estado 

\textbf{Falta la descripción y el pseudo pero me maree, poner ref al pseudo que hay abajo}
\begin{lstlisting}[language={pseudocode},label={lst:classical},caption={Status confirmation.},float=ht]
Algorithm classicalSolver($E, A_E^C$):
	$C = E$
	$C' = \emptyset$
	while $C' \neq  C:$
		$C' = C$
		$R = playerCanForce(C,C \cap M_E)$
		$Tr = C \setminus R$
		$W = ambientCanForce(C, Tr \cup (S_E \setminus (C \cup \Goals)))$
		$C=C \setminus W$
	return C
\end{lstlisting}


\section{Exploración on-the-fly}

El problema de síntesis de controlador ya tiene una solución clásica, por lo que la dificultad del trabajo no consistió en desarrollar un algoritmo que detectara estados ganadores y perdedores de un LTS totalmente explorado. 

El conflicto reside en que al componer distintos DES, la cantidad de estados de la composición es exponencial respecto de los estados en los componentes. Esto es de suma relevancia ya que la solución clásica, que compone toda la planta para luego explorarla, tiene un límite de escalabilidad en el cual la composición de la planta llega al límite de tiempo o memoria, y nunca se llega a la exploración.

Para combatir esto, la exploración on-the-fly clasifica estados como ganadores o perdedores durante la composición. Se espera que con esto sea posible, en primer lugar, cortar la exploración de una rama de la planta que ya se sabe que es perdedora o ganadora, reduciendo así la memoria y tiempo necesarios. Pero más aún, si el estado inicial fuera marcado como ganador o perdedor antes de la composición completa de la planta, ni siquiera sería necesario completar el proceso de composición.

Para incrementar las ramas podadas se utiliza una heurística de exploración Best First Search \cite{tesisDani} que busca ganar controlablemente o perder no controlablemente, para garantizar con la menor exploración posible que el estado actual es ganador o perdedor.

En el peor caso, no se pudo concluir nada antes de componer la planta en su totalidad, se perdió tiempo en los puntos fijos, intentando clasificar estados, y se realiza una última vez el algoritmo clásico con la planta totalmente explorada. Esto garantiza la completitud del algoritmo, como se detalla en mayor profundidad en el capítulo~\ref{chpt:dcs}.

\subsection{Agnosticismo a la heurística}

Una distinción clave del algoritmo \textit{on-the-fly} es que está dividido en dos partes. Por un lado se tiene el algoritmo de exploración responsable de que al final se llegue al resultado correcto, por el otro tenemos una heurística que le brinda la próxima transición a explorar. Ese algoritmo de exploración no puede depender de la heurística, ya que la misma, por su nombre, no garantiza siempre elegir el mejor camino posible, sino solo la mejor aproximación que encuentre. Es en esa correctitud independiente de la heurística donde nuestro trabajo hizo foco.

El proyecto \texttt{MTSA} por el momento cuenta con dos heurísticas \texttt{BFS} para exploración, \textit{Monotonic Abstraction} y \textit{Ready Abstraction}. Ambas son muy buenas y logran gran eficiencia en síntesis de controlador con exploración parcial, pero presentaban un problema.

El algoritmo de exploración había sido desarrollado en conjunto con las heurísticas y si bien esto ayudaba a la eficiencia del mismo, no resultaba agnóstico a las mismas. El nuevo enfoque no depende de la forma de explorar, por ende, da una mayor libertad de investigar a futuro nuevos criterios de evaluación para mejorar la eficiencia de la técnica sin comprometer correctitud ni completitud.














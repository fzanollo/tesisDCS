%Subiría de nivel el “Nuevo algoritmo”. Trataría de explicar tempranamente la idea de construcción de núcleos de posibles zonas perdedoras o ganadoras optimistas y pesimistas y la propagación. Incluso con la formalización primero.

En esta sección presentamos el nuevo algoritmo \DCS, que realiza una exploración sobre la marcha del espacio de estados. Por medio de dicha exploración el algoritmo encuentra una solución al problema composicional de "supervisory control". También discutimos la correctitud y completitud del nuevo algoritmo \DCS. \\

\section{Nuestro enfoque}

Si bien hubo muchos ajustes durante el desarrollo del algoritmo, como se detalló en la sección anterior, destacamos 3 problemas donde pusimos el foco: Propagación muy local, completitud de exploración y encontrar errores. A éstos agregamos un cuarto enfoque, un $invariante$ que mantenemos a lo largo de la exploración.\\

\textbf{Prop local}: Al momento de propagar resultados, tanto estados $\Goals$ como $\Errors$ recurrimos a un punto fijo. De esta forma tenemos en cuenta toda la información acumulada de los estados en cuestión. Si bien esto implica un mayor costo de cómputo, asegura la correcta propagación de información, lo que más adelante facilita por ejemplo la detección de ciclos perdedores.\\

\textbf{Exploración completa}: Nos pareció esencial resolver toda la clasificación necesaria de ganadores y perdedores durante la exploración. Llegado el momento en el que se intenta comenzar a construir el controlador queremos asegurar que no es necesario volver a explorar más transiciones. También queremos asegurar que cuando concluímos que el estado inicial es ganador vamos a poder construir un controlador. Es decir, al momento de la construcción no podemos encontrar información nueva que nos haga cambiar de opinión.

Para esto, tenemos los lemas detallados en la próxima sección, que aseguran que un estado marcado como ganador o perdedor lo es en la planta compuesta totalmente explorada, y nunca puede cambiar su estado. También chequeamos que cuando terminamos de explorar, el estado inicial esté marcado como ganador o perdedor, nunca podemos terminar la exploración porque no hay más transiciones a explorar pero no llegamos a una conclusión sobre el estado inicial.\\

\textbf{Encontrar errores}: La detección de errores tiene tres grandes casos, de los cuales dos son sencillos pero uno trae grandes problemas que lo ponen al mismo nivel de la detección de ganadores. El caso de un $deadlock$, un estado sin transiciones salientes es trivial. Luego la propagación de errores, la clasificación de $s$ como perdedor porque no puede escapar de caer en estados perdedores cuando toma una transición no trae dificultades. El problema radica en detectar los ciclos de estados que pueden extender sus palabras infinitamente pero nunca alcanzarán un estado marcado infinitas veces. 

Sólo podemos concluir que un ciclo es error cuando este ha sido explorado en su completitud y los decendientes que salen del ciclo han sido clasificador. Esto es así debido a la naturaleza optimista de los problemas non-blocking. Si se tiene un ciclo con ningún estado marcado, y todos tienen transiciones controlables a perdedores, pero un solo estado $s$ tiene un camino para llegar a un estado ganador, todos los estados del ciclo son ganadores.

Fue esta necesidad y dificultad para marcar errores lo que nos llevó a incluir el siguiente invariante para la síntesis on-the-fly.\\

\textbf{Invariante}: Intentando resolver el problema del marcado de errores, buscamos una separación fuerte entre los estados $error$ $= L_E$ y los estados para los cuales no tenemos suficiente información para clasificar en este momento $\NONE$.

Como se verá en la propiedad~\ref{def:invariant}, un estado $s$ solo puede seguir sin clasificar (siendo $\NONE$) si con los explorado hasta el momento, y siendo totalmente optimistas sobre las transiciones desconocidas no podemos asegurar que $s$ está condenado a ser perdedor (y tampoco podemos concluir que es ganador).

Al momento de haber explorado todos los decendientes de $s$, incluso si no se exploró toda la planta total, es claro que no importa si se es optimista ($\top$) o pesimista ($\bot$) para saber si $s$ es un estado ganador o perdedor, por lo que nos forzamos por nuestro invariante a clasificarlo. Con esto evitamos las ramas totalmente exploradas pero sin clasificar que traían complicaciones en la figura~\ref{fig:falenciasErrores} y solo permitimos que un estado sea $\NONE$ si tiene un camino a una transición no explorada.


\section{Propuesta de nuevo algoritmo}

\input{pseudocode.tex}

\FloatBarrier

\section{Demostración de corectitud y completitud}
\input{prueba.tex}

\section{Demostración de Lemas}
\input{lemmaProofs.tex}
